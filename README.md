# Test Technique - IngÃ©nieur IA GÃ©nÃ©rative

Ce projet contient les implÃ©mentations pour le test technique d'ingÃ©nieur IA gÃ©nÃ©rative, divisÃ© en trois parties principales.

## ğŸ“ Structure du Projet

```
entretient/
â”œâ”€â”€ chatbot-ia-generative/    # Partie 1 & 2 : Chatbot avec recherche web
â”œâ”€â”€ vlm_project/              # Partie 3 : DÃ©mo VLM avec Qwen2.5-VL
â””â”€â”€ README.md                 # Ce fichier
```

## ğŸš€ Parties du Test

### Partie 1 & 2 : Chatbot IA avec Recherche Web
Un chatbot intelligent qui combine recherche web en temps rÃ©el et gÃ©nÃ©ration de rÃ©ponses contextuelles.

**FonctionnalitÃ©s principales :**
- Recherche web intelligente multi-sources
- GÃ©nÃ©ration de rÃ©ponses avec OpenRouter (Qwen-2.5-32B)
- Citations inline des sources [1], [2] comme Claude
- Interface React moderne et Ã©purÃ©e

[â†’ Voir les dÃ©tails d'installation et d'utilisation](./chatbot-ia-generative/README.md)

### Partie 3 : Vision Language Model (VLM)
DÃ©monstration d'un modÃ¨le VLM local utilisant Qwen2.5-VL-3B.

**FonctionnalitÃ©s :**
- Analyse d'images locales avec vLLM
- RÃ©ponses aux questions sur le contenu visuel
- OptimisÃ© pour Mac Apple Silicon

[â†’ Voir les dÃ©tails et l'analyse thÃ©orique](./vlm_project/README.md)

## ğŸ›  Installation Rapide

### PrÃ©requis
- Python 3.12 (pour vLLM)
- Node.js 16+
- 8GB+ de RAM

### Installation ComplÃ¨te
```bash
# 1. Cloner le projet
git clone https://github.com/ibzzo/tw3interviewme.git
cd entretient

# 2. Installer le chatbot
cd chatbot-ia-generative
pip install -r requirements.txt
npm install --prefix frontend

# 3. Installer le VLM (optionnel)
cd ../vlm_project
python -m venv venv_vlm
source venv_vlm/bin/activate
pip install -r requirements.txt
```

## ğŸ“ Configuration

CrÃ©er un fichier `.env` dans `chatbot-ia-generative/` :
```env
OPENROUTER_API_KEY=your_key_here
SERPAPI_API_KEY=your_key_here
```

## ğŸš€ Lancement

### Chatbot
```bash
cd chatbot-ia-generative
./start.sh
```
â†’ Frontend : http://localhost:3000
â†’ Backend : http://localhost:8000

### VLM Demo
```bash
cd vlm_project
./start_vllm.sh        # Terminal 1
python vlm_demo.py     # Terminal 2
```

## ğŸ“š Documentation
- [Chatbot - Documentation complÃ¨te](./chatbot-ia-generative/README.md)
- [VLM - Analyse thÃ©orique et pratique](./vlm_project/README.md)

## ğŸ— Architecture

### Chatbot
- **Backend** : Django REST Framework + OpenRouter API
- **Frontend** : React + TypeScript + Styled Components
- **Recherche** : Multi-sources (SerpAPI, DuckDuckGo, Tavily)

### VLM
- **ModÃ¨le** : Qwen2.5-VL-3B-Instruct
- **Serveur** : vLLM optimisÃ© pour CPU
- **Interface** : Script Python interactif

## ğŸ‘¤ Auteur
Ibrahim Adiao

## ğŸ“„ License
Ce projet est dÃ©veloppÃ© dans le cadre d'un test technique.